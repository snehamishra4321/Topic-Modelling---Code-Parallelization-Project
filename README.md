# Topic-Modelling-Code-Parallelization-Project
- Performed topic modelling using Latent Dirichlet Allocation (LDA) to discover trends in Machine learning over past 10 years using a coagulated
dataset of NIPS research papers. Implemented in Python (Jupyter Notebook) parallelizing the code reducing computation time by 75%.<br>
- Identified evolution of major topics in machine learning using zero-shot classification and created impactful visualizations using seaborn, matplotlib
and plotly packages<br>
- Latent Dirichlet Allocation (LDA) is a type of topic modeling technique in which documents are modeled as a mixture of topics. <br>
- Each document is composed of a mixture of topics, and each topic is composed of a mixture of words. <br>
- The goal of LDA is to make inferences about the underlying topics in a collection of documents. <br>
- LDA can be used to discover hidden themes in large collections of documents, such as text corpora, webpages, blog posts, or even tweets. <br>
- It can also be used to identify topics in documents and classify them into categories. <br>
- By using LDA, we can identify topics in documents without manually reading through each one. This can be very useful for quickly summarizing large collections of documents. <br>

### Code Parallelization in Python
- Parallelization in Python is the process of running multiple processes simultaneously in order to increase the speed and efficiency of a program. <br>
- It is done by dividing a task into smaller sub-tasks, which are then run on different processors or threads. <br>
- By doing this, the total amount of time needed to complete the task is reduced. <br>
- There are various libraries available in Python that can be used to perform parallelization such as multiprocessing, concurrent.futures, and threading.<br> 
- Additionally, there are also frameworks such as Dask, Ray, and Spark that can be used to efficiently scale up parallel computations.<br>
