# Topic-Modelling-Code-Parallelization-Project
- Performed topic modelling using Latent Dirichlet Allocation (LDA) to discover trends in Machine learning over past 10 years using a coagulated
dataset of NIPS research papers. Implemented in Python (Jupyter Notebook) parallelizing the code reducing computation time by 75%.<br>
- Identified evolution of major topics in machine learning using zero-shot classification and created impactful visualizations using seaborn, matplotlib
and plotly packages<br>
- Latent Dirichlet Allocation (LDA) is a type of topic modeling technique in which documents are modeled as a mixture of topics. <br>
- Each document is composed of a mixture of topics, and each topic is composed of a mixture of words. <br>
- The goal of LDA is to make inferences about the underlying topics in a collection of documents. <br>
- LDA can be used to discover hidden themes in large collections of documents, such as text corpora, webpages, blog posts, or even tweets. <br>
- It can also be used to identify topics in documents and classify them into categories. <br>
- By using LDA, we can identify topics in documents without manually reading through each one. This can be very useful for quickly summarizing large collections of documents. <br>
